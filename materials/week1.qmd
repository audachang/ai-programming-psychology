---
title: "Week 1: Foundations of Reproducible Science"
subtitle: "Psychology 7029: Programming and AI Applications"
author: "Erik Chihhung Chang"
date: "2027-02-15"
format:
  html:
    toc: true
    code-fold: false
    theme: cosmo
  gfm:
    preview-mode: raw
jupyter: python3
---

# üëã Welcome to the Digital Lab

**Course Philosophy:**
This course is not just about writing code; it is about building a **reproducible research pipeline**. In traditional psychology, we often click through menus in SPSS or E-Prime. In this course, we script everything. This ensures that if you (or a reviewer) come back to your data in 5 years, you can get the exact same results.

**Today's Objectives:**
1.  **Verify** our scientific environment (Python/Anaconda).
2.  **Configure** Git for version control (Your digital lab notebook).
3.  **Demonstrate** why we use Numpy instead of standard lists (Speed).
4.  **Structure** behavioral data using Pandas.

---

# 1. Environment Check

Before we can analyze brain data or predict behavior, we must ensure our tools are sharp. We will verify that we are running a compatible version of Python.

```{python}
import sys
import os

print(f"‚úÖ Python Executable: {sys.executable}")
print(f"‚úÖ Python Version: {sys.version.split()[0]}")

# We need at least Python 3.8 for most modern Machine Learning libraries
if sys.version_info < (3, 8):
    raise RuntimeError("‚ùå Your Python version is too old! Please update Anaconda.")
else:
    print("üéâ Environment looks good!")

```

---

# 2. Git & GitHub Configuration

Reproducibility means version control. We will use Git to track changes in our experiments.

**Step 2.1: Check if Git is installed**

```{python}
#| output: asis
# Run a terminal command using the '!' prefix (Jupyter magic)
!git --version

```

**Step 2.2: Configure your identity**
Run the cell below. If this is your first time, uncomment the lines and replace with your details. This tells Git who is making the changes.

```{python}
#| eval: false
# UNCOMMENT AND RUN THIS ONCE
# !git config --global user.name "Your Name"
# !git config --global user.email "your.email@university.edu"

# Verify setup
!git config --list | grep user

```

**Step 2.3: SSH Key Generation (Manual Step)**
To push code to GitHub without entering a password every time, we use SSH keys.
*Open your terminal (Git Bash on Windows) and run:*

```bash
ssh-keygen -t ed25519 -C "your.email@university.edu"
cat ~/.ssh/id_ed25519.pub

```

*Copy the output and paste it into GitHub -> Settings -> SSH and GPG Keys.*

---

# 3. The Need for Speed: Numpy vs. Lists

Psychological experiments often require millisecond precision, and fMRI analysis involves processing millions of voxels. Standard Python lists are too slow for this. We use **Numpy** (Numerical Python).

Let's simulate a massive dataset of **1 million reaction times**.

```{python}
import numpy as np
import time

# Create a standard Python list with 1 million items
py_list = list(range(1_000_000))

# Create a Numpy array with the same items
np_array = np.array(range(1_000_000))

print("Data generated.")

```

**Test 1: Python Loop (The Slow Way)**
Imagine we want to convert these reaction times from seconds to milliseconds (multiply by 1000).

```{python}
start_time = time.time()

# We have to loop through every single item one by one
py_result = [x * 1000 for x in py_list]

end_time = time.time()
py_duration = end_time - start_time
print(f"üê¢ Python Loop Time: {py_duration:.5f} seconds")

```

**Test 2: Numpy Vectorization (The Fast Way)**
Numpy performs the operation on the entire block of memory at once.

```{python}
start_time = time.time()

# No loop! We just multiply the array.
np_result = np_array * 1000

end_time = time.time()
np_duration = end_time - start_time
print(f"üöÄ Numpy Vector Time: {np_duration:.5f} seconds")

# Calculate speedup
speedup = py_duration / np_duration
print(f"\n‚ö° Numpy is {speedup:.1f}x faster than standard Python!")

```

**Takeaway:** Never write `for` loops to process data if you can use Numpy vectorization.

---

# 4. Data Structures: Pandas DataFrames

In this course, your raw data (logs) and processed data will live in **Pandas DataFrames**. Think of them as "Excel on steroids."

Let's create a "Mock" Psychological Dataset.

**Scenario:** A simple Go/No-Go task.

* **Subject:** 001
* **Trials:** 1-5
* **Condition:** Go vs. No-Go
* **RT:** Reaction Time in seconds

```{python}
import pandas as pd

# Creating data from a dictionary
data = {
    'subject_id': ['s001', 's001', 's001', 's001', 's001'],
    'trial_index': [1, 2, 3, 4, 5],
    'condition': ['Go', 'Go', 'No-Go', 'Go', 'No-Go'],
    'accuracy': [1, 1, 0, 1, 1], # 1 = Correct, 0 = Error
    'rt_sec': [0.450, 0.520, 0.310, np.nan, 0.0] 
}

df = pd.DataFrame(data)

# Display the dataframe
print("--- Raw Behavioral Log ---")
display(df)

```

**Step 4.1: Handling Dirty Data**
Real data is messy. Note trial 4 has `NaN` (Not a Number) ‚Äî perhaps the participant sneezed and didn't press a key?

```{python}
# Check for missing values
print(f"Missing values per column:\n{df.isnull().sum()}\n")

# Strategy: Drop trials where no response was recorded (if response was required)
# Or fill them? For now, let's drop rows with missing RTs to calculate the mean.
clean_df = df.dropna(subset=['rt_sec'])

print(f"Original trial count: {len(df)}")
print(f"Clean trial count: {len(clean_df)}")

```

**Step 4.2: Feature Engineering (Preview)**
Let's calculate the average Reaction Time for "Go" trials only.

```{python}
# Filter for 'Go' condition AND correct trials
go_trials = clean_df[
    (clean_df['condition'] == 'Go') & 
    (clean_df['accuracy'] == 1)
]

mean_rt = go_trials['rt_sec'].mean()
print(f"üß† Mean Correct RT (Go Trials): {mean_rt:.3f} seconds")

```

---

# 5. Assignment 1: Hello GitHub

**Due:** Next Week
**Goal:** Initialize your course repository.

**Instructions:**

1. Create a new repository on GitHub named `psych-7029-yourname`.
2. Clone it to your local machine using the command line:
```bash
git clone git@github.com:yourusername/psych-7029-yourname.git

```


3. Create a folder named `week_01`.
4. Save this notebook (as `.ipynb` or `.qmd`) into that folder.
5. Commit and Push:
```bash
git add .
git commit -m "feat: added week 1 notes"
git push origin main

```


6. **Submission:** Submit the URL of your repository to Google Classroom.
