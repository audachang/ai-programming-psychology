# Week 10: Basic ML Algorithms: Regression & Classification\n# 第十週：基礎機器學習演算法：迴歸與分類\n\n> **Date 日期**: 2026/04/30  \n> **Topic 主題**: Predictive Modeling 預測模型\n\n---\n\n## Learning Objectives 學習目標\n\n1. 理解迴歸與分類任務的區別與常見應用。\n2. 掌握線性迴歸 (Linear Regression) 的基本原理與實作，用於連續變數預測。\n3. 學習羅吉斯迴歸 (Logistic Regression) 和支援向量機 (SVM) 的概念，用於二元分類問題。\n4. 熟悉分類模型的核心評估指標：準確度 (Accuracy)、精確度 (Precision)、召回率 (Recall)、F1 分數、混淆矩陣 (Confusion Matrix)。\n5. 理解接收者操作特徵曲線 (ROC Curve) 和曲線下面積 (AUC) 在評估分類模型中的應用。\n\n---\n\n## 1. Regression: Predicting Continuous Variables\n## 1. 迴歸：預測連續變數\n\n迴歸分析是機器學習中用於預測連續數值型輸出變數的任務。最基本的迴歸模型是線性迴歸。\n\n### 1.1 Linear Regression 線性迴歸\n\n-   **定義**: 找出輸入特徵與連續輸出變數之間的一條最佳線性關係。目標是最小化預測值與實際值之間的平方誤差 (Mean Squared Error)。\n-   **心理學應用**: 根據刺激強度預測反應時間；根據壓力水平預測主觀幸福感評分。\n\n**模型形式 (Model Form):**\n$y = \beta_0 + \beta_1 x_1 + \\dots + \beta_n x_n + \\epsilon$\n其中 $y$ 是預測目標， $x_i$ 是特徵， $\beta_i$ 是模型的係數 (權重)， $\beta_0$ 是截距， $\\epsilon$ 是誤差項。\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Generate synthetic data for demonstration\n# 生成用於示範的合成資料\nnp.random.seed(0)\nX = 2 * np.random.rand(100, 1) # Feature (e.g., stimulus intensity)\ny = 4 + 3 * X + np.random.randn(100, 1) # Target (e.g., reaction time)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the model\n# 建立並訓練模型\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Coefficients (斜率): {model.coef_[0][0]:.2f}\")\nprint(f\"Intercept (截距): {model.intercept_[0]:.2f}\")\nprint(f\"Mean Squared Error (均方誤差): {mse:.2f}\")\nprint(f\"R-squared (R平方): {r2:.2f}\")\n\n# Plotting results\nplt.figure(figsize=(8, 6))\nplt.scatter(X_test, y_test, color=\'blue\', label=\'Actual data\')\nplt.plot(X_test, y_pred, color=\'red\', linewidth=2, label=\'Linear Regression\')\nplt.xlabel(\"Feature (X)\")\nplt.ylabel(\"Target (y)\")\nplt.title(\"Linear Regression Example\")\nplt.legend()\nplt.grid(True)\n# plt.show() # Uncomment to display plot\n```\n\n---\n\n## 2. Classification: Predicting Categorical Outcomes\n## 2. 分類：預測類別結果\n\n分類是機器學習中用於預測離散型（類別型）輸出變數的任務。常見的分類演算法包括羅吉斯迴歸和支援向量機。\n\n### 2.1 Logistic Regression 羅吉斯迴歸\n\n-   **定義**: 儘管名稱帶有「迴歸」，但羅吉斯迴歸是一種用於二元分類問題的線性模型。它使用 sigmoid 函數將線性模型的輸出壓縮到 0 到 1 之間，解釋為屬於某一類別的機率。\n-   **心理學應用**: 根據腦活動模式預測個體是否患有特定精神疾病；根據人口統計學資訊預測是否會對某個廣告產生購買行為。\n\n**Sigmoid 函數 (Sigmoid Function):**\n$\sigma(z) = \\frac{1}{1 + e^{-z}}$\n\n```python\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Generate synthetic data for binary classification\n# 生成用於二元分類的合成資料\nnp.random.seed(1)\nX_clf = np.random.rand(100, 2) * 10 # 100 samples, 2 features\ny_clf = (X_clf[:, 0] + X_clf[:, 1] > 10).astype(int) # Binary labels (0 or 1)\n\n# Split data\nX_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n\n# Create and train the model\nmodel_lr = LogisticRegression(random_state=42)\nmodel_lr.fit(X_train_clf, y_train_clf)\n\n# Make predictions\ny_pred_lr = model_lr.predict(X_test_clf)\n\n# Evaluate the model\nprint(\"Logistic Regression Evaluation:\")\nprint(f\"Accuracy: {accuracy_score(y_test_clf, y_pred_lr):.2f}\")\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_clf, y_pred_lr))\nprint(\"Classification Report:\\n\", classification_report(y_test_clf, y_pred_lr))\n```\n\n### 2.2 Support Vector Machine (SVM) 支援向量機\n\n-   **定義**: SVM 旨在找到一個最佳的超平面 (hyperplane) 來將不同類別的資料點分開，並使距離超平面最近的訓練資料點 (支援向量) 到超平面的距離最大化。\n-   **核心思想**: 找到最大邊界 (Maximum Margin) 分類器。\n-   **心理學應用**: 從腦影像數據中區分不同認知任務狀態；根據眼動追蹤數據分類視覺注意模式。\n\n```python\nfrom sklearn.svm import SVC\n\n# Create and train an SVM model\nmodel_svm = SVC(kernel=\'linear\', random_state=42) # Using a linear kernel for simplicity\nmodel_svm.fit(X_train_clf, y_train_clf)\n\n# Make predictions\ny_pred_svm = model_svm.predict(X_test_clf)\n\n# Evaluate the model\nprint(\"\nSupport Vector Machine (SVM) Evaluation:\")\nprint(f\"Accuracy: {accuracy_score(y_test_clf, y_pred_svm):.2f}\")\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_clf, y_pred_svm))\nprint(\"Classification Report:\\n\", classification_report(y_test_clf, y_pred_svm))\n```\n\n---\n\n## 3. Classification Model Evaluation Metrics 分類模型評估指標\n\n僅僅依靠準確度 (Accuracy) 可能不足以評估分類模型的性能，特別是在類別不平衡的資料集中。我們需要更全面的指標。\n\n### 3.1 Confusion Matrix 混淆矩陣\n\n混淆矩陣是一個表格，用來描述分類模型在測試集上的表現。它將實際類別和模型預測的類別進行比較。\n\n|                   | **預測為正 (Predicted Positive)** | **預測為負 (Predicted Negative)** |\n| :---------------- | :------------------------------- | :------------------------------- |\n| **實際為正 (Actual Positive)** | 真陽性 (True Positive, TP)       | 偽陰性 (False Negative, FN)      |\n| **實際為負 (Actual Negative)** | 偽陽性 (False Positive, FP)      | 真陰性 (True Negative, TN)       |\n\n-   **TP**: 正確預測為正類別。\n-   **FN**: 錯誤預測為負類別 (遺漏)。\n-   **FP**: 錯誤預測為正類別 (誤報)。\n-   **TN**: 正確預測為負類別。\n\n### 3.2 Key Metrics 關鍵指標\n\n-   **準確度 (Accuracy)**: 正確預測的樣本總數佔總樣本數的比例。\n    $Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$\n-   **精確度 (Precision)**: 預測為正類別的樣本中，實際為正類別的比例。\n    $Precision = \\frac{TP}{TP + FP}$\n-   **召回率 (Recall) / 敏感度 (Sensitivity)**: 實際為正類別的樣本中，被正確預測為正類別的比例。\n    $Recall = \\frac{TP}{TP + FN}$\n-   **F1 分數 (F1-Score)**: 精確度與召回率的調和平均值，平衡兩者。\n    $F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}$\n\n### 3.3 ROC Curve and AUC ROC 曲線與 AUC\n\n**ROC 曲線 (Receiver Operating Characteristic Curve):**\n-   繪製在不同分類閾值下，真陽性率 (True Positive Rate, TPR) 對偽陽性率 (False Positive Rate, FPR) 的曲線。\n-   **TPR (召回率)**: $TPR = \\frac{TP}{TP + FN}$\n-   **FPR**: $FPR = \\frac{FP}{FP + TN}$\n-   曲線越靠近左上角，模型性能越好。\n\n**AUC (Area Under the ROC Curve):**\n-   ROC 曲線下的面積。AUC 值介於 0 到 1 之間。\n-   **解釋**: 模型區分正負類別的能力。AUC 為 0.5 表示模型表現與隨機猜測無異；AUC 越接近 1，模型性能越好。\n\n```python\nfrom sklearn.metrics import roc_curve, auc\n\n# Get probabilities for ROC curve\n# 取得用於 ROC 曲線的機率值\ny_prob_lr = model_lr.predict_proba(X_test_clf)[:, 1] # Probability of belonging to class 1\n\n# Calculate ROC curve\n# 計算 ROC 曲線\nfpr, tpr, thresholds = roc_curve(y_test_clf, y_prob_lr)\nroc_auc = auc(fpr, tpr)\n\nprint(f\"\\nROC AUC Score: {roc_auc:.2f}\")\n\n# Plotting ROC Curve (Conceptual)\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color=\'darkorange\', lw=2, label=\'ROC curve (area = %0.2f)\' % roc_auc)\nplt.plot([0, 1], [0, 1], color=\'navy\', lw=2, linestyle=\'--\')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\'False Positive Rate (FPR)\')\nplt.ylabel(\'True Positive Rate (TPR)\')\nplt.title(\'Receiver Operating Characteristic (ROC) Curve\')\nplt.legend(loc=\"lower right\")\nplt.grid(True)\n# plt.show() # Uncomment to display plot\n```\n\n---\n\n## 4. Lab Activity: Predicting Trial Errors\n## 4. 實作活動：預測試驗錯誤\n\n**目標**: 訓練一個模型來預測受試者在下一個試驗中是否會犯錯，基於他們在前一個試驗中的反應時間 (RT)。\n\n**Goal**: Train a model to predict if a subject will make an error on the *next* trial based on their Reaction Time (RT) in the *previous* trial.\n\n### 任務 Task\n\n1.  生成一個模擬的行為資料集，包含 `trial_num`, `prev_rt`, `current_error` (二元變數)。\n2.  將資料分割為訓練集和測試集。\n3.  訓練一個 `LogisticRegression` 或 `SVC` 模型。\n4.  使用混淆矩陣、準確度、精確度、召回率和 F1 分數評估模型性能。\n5.  計算並列印模型的 ROC AUC 分數。\n\n```python\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n\n# 1. Generate synthetic behavioral data\n# 1. 生成合成行為資料\nnp.random.seed(42)\nn_trials = 200\n\n# Simulate previous reaction times (e.g., faster RTs might lead to fewer errors)\n# 模擬先前的反應時間（例如，較快的 RT 可能導致較少錯誤）\nprev_rt = np.random.normal(loc=400, scale=80, size=n_trials)\nprev_rt = np.clip(prev_rt, 200, 800) # Clip values to a reasonable range\n\n# Simulate current error (binary: 0 for correct, 1 for error)\n# A simple probabilistic relationship: faster RT -> lower chance of error\n# 模擬當前錯誤（二元：0 表示正確，1 表示錯誤）\n# 一個簡單的機率關係：RT 越快 -> 錯誤機率越低\nerror_probability = 1 / (1 + np.exp(-(prev_rt - 450) / 70)) # Sigmoid-like function\ncurrent_error = (np.random.rand(n_trials) < error_probability).astype(int)\n\ndf_trial_data = pd.DataFrame({\n    \'prev_rt\': prev_rt,\n    \'current_error\': current_error\n})\n\nprint(\"Synthetic Trial Data (first 5 rows):\")\nprint(df_trial_data.head())\n\n# Define features (X) and target (y)\nX = df_trial_data[[\'prev_rt\']]\ny = df_trial_data[\'current_error\']\n\n# 2. Split data into training and testing sets\n# 2. 將資料分割為訓練集和測試集\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n\nprint(f\"\\nTraining samples: {len(X_train)}, Error rate in train: {y_train.mean():.2f}\")\nprint(f\"Testing samples: {len(X_test)}, Error rate in test: {y_test.mean():.2f}\")\n\n# 3. Train a Logistic Regression model\n# 3. 訓練羅吉斯迴歸模型\nmodel_predict_error = LogisticRegression(random_state=42)\nmodel_predict_error.fit(X_train, y_train)\n\n# 4. Evaluate model performance\n# 4. 評估模型性能\ny_pred_error = model_predict_error.predict(X_test)\ny_prob_error = model_predict_error.predict_proba(X_test)[:, 1]\n\nprint(\"\\n--- Model Evaluation ---\")\nprint(f\"Accuracy: {accuracy_score(y_test, y_pred_error):.2f}\")\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_error))\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_error))\n\n# 5. Calculate and print ROC AUC score\n# 5. 計算並列印 ROC AUC 分數\nroc_auc_val = roc_auc_score(y_test, y_prob_error)\nprint(f\"ROC AUC Score: {roc_auc_val:.2f}\")\n```\n\n---\n\n## 5. References 參考資料\n\n- **Scikit-learn Logistic Regression**: [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n- **Scikit-learn SVM**: [https://scikit-learn.org/stable/modules/svm.html](https://scikit-learn.org/stable/modules/svm.html)\n- **Evaluation Metrics (Scikit-learn)**: [https://scikit-learn.org/stable/modules/model_evaluation.html](https://scikit-learn.org/stable/modules/model_evaluation.html)\n- **ROC Curve Explained**: [https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc)\n