# Week 1: Orientation, Python Environment Setup & Basic Libraries
# Á¨¨‰∏ÄÈÄ±ÔºöË™≤Á®ã‰ªãÁ¥π„ÄÅPython Áí∞Â¢ÉÂª∫ÁΩÆËàáÂü∫Á§éÂáΩÂºèÂ∫´

> **Date Êó•Êúü**: 2026/02/26  
> **Topic ‰∏ªÈ°å**: Setting the Stage for Scientific Computing Â•†ÂÆöÁßëÂ≠∏Ë®àÁÆóÁöÑÂü∫Á§é

---

## Learning Objectives Â≠∏ÁøíÁõÆÊ®ô

1. ÁêÜËß£„ÄåÂÜçÁèæÊÄßÂç±Ê©ü„Äç(Reproducibility Crisis) ‰ª•ÂèäÁ®ãÂºèÁ¢ºÂú®ÁßëÂ≠∏Á†îÁ©∂‰∏≠ÁöÑÊ†∏ÂøÉËßíËâ≤
2. ÂÆâË£ùËàáË®≠ÂÆö VS Code„ÄÅAnaconda/MiniforgeÔºåÂª∫Á´ãËôõÊì¨Áí∞Â¢É
3. Ë§áÁøí Python Âü∫Êú¨Ê¶ÇÂøµÔºöÂèØËÆä/‰∏çÂèØËÆäÂûãÂà•„ÄÅList Comprehension„ÄÅÊ®°ÁµÑÂåñË®≠Ë®à
4. Â≠∏ÊúÉ‰ΩøÁî® **NumPy** ÈÄ≤Ë°åÈ´òÊïàËÉΩÈô£ÂàóÊìç‰Ωú

---

## 1. The Reproducibility Crisis & Why Code Matters
## 1. ÂÜçÁèæÊÄßÂç±Ê©üËàáÁ®ãÂºèÁ¢ºÁöÑÈáçË¶ÅÊÄß

Psychology has faced a significant "Reproducibility Crisis"‚Äîmany published experimental findings cannot be replicated. One major reason is that researchers often rely on manual procedures, point-and-click software, and undocumented analysis steps.

ÂøÉÁêÜÂ≠∏ÁïåÈù¢Ëá®Âö¥ÈáçÁöÑ„ÄåÂÜçÁèæÊÄßÂç±Ê©ü„Äç‚Äî‚ÄîË®±Â§öÂ∑≤ÁôºË°®ÁöÑÂØ¶È©óÁµêÊûúÁÑ°Ê≥ïË¢´ÈáçË§áÈ©óË≠â„ÄÇ‰∏ªË¶ÅÂéüÂõ†‰πã‰∏ÄÊòØÁ†îÁ©∂ËÄÖÁ∂ìÂ∏∏‰ª∞Ë≥¥ÊâãÂãïÊìç‰Ωú„ÄÅÈªûÊìäÂºèËªüÈ´îÂíåÊú™Ë®òÈåÑÁöÑÂàÜÊûêÊ≠•È©ü„ÄÇ

**How code solves this Á®ãÂºèÁ¢ºÂ¶Ç‰ΩïËß£Ê±∫ÈÄôÂÄãÂïèÈ°å:**

- **Transparency ÈÄèÊòéÊÄß**: Every step is documented in the script
- **Reproducibility ÂèØÈáçË§áÊÄß**: Anyone can re-run the same analysis
- **Version Control ÁâàÊú¨ÊéßÂà∂**: Changes are tracked with Git
- **Automation Ëá™ÂãïÂåñ**: Reduce human error in repetitive tasks

---

## 2. The Stack: Development Environment
## 2. ÈñãÁôºÁí∞Â¢ÉÂ∑•ÂÖ∑ÁµÑ

### 2.1 VS Code

[Visual Studio Code](https://code.visualstudio.com/) is a free, powerful code editor with excellent Python support.

**Êé®Ëñ¶Êì¥ÂÖÖÂ•ó‰ª∂ Recommended Extensions:**

```
- Python (Microsoft)
- Jupyter (Microsoft)
- Pylance (language server)
- GitLens (Git visualization)
```

### 2.2 Anaconda / Miniforge

[Miniforge](https://github.com/conda-forge/miniforge) is a lightweight Conda installer that defaults to the `conda-forge` channel‚Äîideal for PsychoPy dependencies.

Miniforge ÊòØ‰∏ÄÂÄãËºïÈáèÁ¥öÁöÑ Conda ÂÆâË£ùÁ®ãÂºèÔºåÈ†êË®≠‰ΩøÁî® `conda-forge` È†ªÈÅìÔºåÂ∞ç PsychoPy ÁöÑÁõ∏‰æùÊÄßÊîØÊè¥ËºÉ‰Ω≥„ÄÇ

### 2.3 Virtual Environments ËôõÊì¨Áí∞Â¢É

Virtual environments isolate project dependencies so they don't conflict with each other.

ËôõÊì¨Áí∞Â¢ÉÂ∞áÂ∞àÊ°àÁöÑÁõ∏‰æùÂ•ó‰ª∂ÈöîÈõ¢Èñã‰æÜÔºåÈÅøÂÖç‰∫íÁõ∏Ë°ùÁ™Å„ÄÇ

```bash
# Create a new environment Âª∫Á´ãÊñ∞Áí∞Â¢É
conda create -n psychopy_env python=3.10

# Activate ÂïüÂãïÁí∞Â¢É
conda activate psychopy_env

# Install packages ÂÆâË£ùÂ•ó‰ª∂
pip install psychopy numpy pandas matplotlib seaborn

# Deactivate when done ÂÆåÊàêÂæåÂÅúÁî®
conda deactivate

# List all environments ÂàóÂá∫ÊâÄÊúâÁí∞Â¢É
conda env list

# Remove an environment ÁßªÈô§Áí∞Â¢É
conda env remove -n psychopy_env
```

**`conda` vs `venv`:**

| Feature | `conda` | `venv` |
|---------|---------|--------|
| Manages non-Python deps | ‚úÖ | ‚ùå |
| Cross-platform binaries | ‚úÖ | ‚ùå |
| Built into Python | ‚ùå | ‚úÖ |
| Environment size | Larger | Smaller |

> **Recommendation Âª∫Ë≠∞**: Use `conda` for this course because PsychoPy has complex C-level dependencies (e.g., `wxPython`).

---

## 3. Python Refresher 
## 3. Python Ë§áÁøí

### 3.1 Mutable vs. Immutable Types ÂèØËÆäËàá‰∏çÂèØËÆäÂûãÂà•

```python
# Immutable types: int, float, str, tuple
# ‰∏çÂèØËÆäÂûãÂà•Ôºö‰øÆÊîπÊôÇÊúÉÂª∫Á´ãÊñ∞Áâ©‰ª∂
x = 10
y = x
x = 20
print(y)  # Still 10 ‚Äî integers are immutable

name = "PsychoPy"
# name[0] = "p"  # ‚ùå TypeError: strings are immutable

# Mutable types: list, dict, set
# ÂèØËÆäÂûãÂà•Ôºö‰øÆÊîπÊúÉÂΩ±ÈüøÊâÄÊúâÂèÉÁÖß
colors = ["red", "green", "blue"]
backup = colors        # Both point to the SAME list!
colors.append("yellow")
print(backup)  # ['red', 'green', 'blue', 'yellow'] ‚Äî also changed!

# Safe copy ÂÆâÂÖ®Ë§áË£Ω
backup = colors.copy()  # or colors[:]
```

**Why this matters in experiments ÁÇ∫‰ªÄÈ∫ºÈÄôÂú®ÂØ¶È©ó‰∏≠ÂæàÈáçË¶Å:**

When creating trial lists, accidentally sharing a mutable reference can cause conditions to "leak" between trials.

Âª∫Á´ãË©¶È©óÂàóË°®ÊôÇÔºåËã•‰∏çÂ∞èÂøÉÂÖ±‰∫´ÂèØËÆäÂèÉÁÖßÔºåÂèØËÉΩÂ∞éËá¥Ê¢ù‰ª∂Âú®Ë©¶È©óÈñì„ÄåÊ¥©Êºè„Äç„ÄÇ

### 3.2 List Comprehensions ÂàóË°®Êé®Â∞éÂºè

```python
# Traditional loop ÂÇ≥Áµ±Ëø¥Âúà
squares = []
for i in range(10):
    squares.append(i ** 2)

# List comprehension ÂàóË°®Êé®Â∞éÂºè ‚Äî compact & Pythonic
squares = [i ** 2 for i in range(10)]

# With condition Âä†ÂÖ•Ê¢ù‰ª∂ÁØ©ÈÅ∏
even_squares = [i ** 2 for i in range(10) if i % 2 == 0]
# [0, 4, 16, 36, 64]

# Practical: Generate stimulus positions ÂØ¶Áî®ÔºöÁîüÊàêÂà∫ÊøÄ‰ΩçÁΩÆ
positions = [(x, y) for x in [-200, 0, 200] for y in [-200, 0, 200]]
```

### 3.3 Modular Design Ê®°ÁµÑÂåñË®≠Ë®à

```python
# experiment_utils.py ‚Äî A reusable module for experiments
# ‰∏ÄÂÄãÂèØÈáçË§á‰ΩøÁî®ÁöÑÂØ¶È©óÂ∑•ÂÖ∑Ê®°ÁµÑ

def generate_trial_list(conditions, n_repeats=10):
    """
    Generate a randomized trial list.
    Áî¢ÁîüÈö®Ê©üÂåñÁöÑË©¶È©óÂàóË°®„ÄÇ
    
    Parameters:
        conditions (list): List of condition labels
        n_repeats (int): Number of repetitions per condition
    
    Returns:
        list: Shuffled trial list
    """
    import random
    trials = conditions * n_repeats
    random.shuffle(trials)
    return trials


def calculate_accuracy(responses, correct_answers):
    """Calculate proportion correct. Ë®àÁÆóÊ≠£Á¢∫Áéá„ÄÇ"""
    assert len(responses) == len(correct_answers)
    hits = sum(r == c for r, c in zip(responses, correct_answers))
    return hits / len(responses)
```

```python
# main_experiment.py ‚Äî Using the module
# Âú®‰∏ªÁ®ãÂºè‰∏≠‰ΩøÁî®Ê®°ÁµÑ
from experiment_utils import generate_trial_list, calculate_accuracy

conditions = ["congruent", "incongruent"]
trials = generate_trial_list(conditions, n_repeats=20)
print(f"Total trials: {len(trials)}")
# Total trials: 40
```

---

## 4. Introduction to NumPy
## 4. NumPy ÂÖ•ÈñÄ

NumPy is the foundation of scientific computing in Python. It provides fast, memory-efficient array operations essential for coordinate systems, timing, and randomization in experiments.

NumPy ÊòØ Python ÁßëÂ≠∏Ë®àÁÆóÁöÑÂü∫Áü≥ÔºåÊèê‰æõÂø´ÈÄü„ÄÅË®òÊÜ∂È´îÊïàÁéáÈ´òÁöÑÈô£ÂàóÈÅãÁÆóÔºåÂú®ÂØ¶È©ó‰∏≠ÁöÑÂ∫ßÊ®ôÁ≥ªÁµ±„ÄÅË®àÊôÇÂíåÈö®Ê©üÂåñ‰∏çÂèØÊàñÁº∫„ÄÇ

### 4.1 Creating Arrays Âª∫Á´ãÈô£Âàó

```python
import numpy as np

# From a list ÂæûÂàóË°®Âª∫Á´ã
reaction_times = np.array([0.452, 0.389, 0.521, 0.467, 0.498])

# Useful constructors Â∏∏Áî®Âª∫ÊßãÂáΩÂºè
zeros = np.zeros(10)                  # 10 zeros
ones = np.ones((3, 4))                # 3√ó4 matrix of ones
sequence = np.arange(0, 1, 0.1)       # [0.0, 0.1, 0.2, ..., 0.9]
linspace = np.linspace(0, 2*np.pi, 100)  # 100 points from 0 to 2œÄ
```

### 4.2 Array Operations Èô£ÂàóÈÅãÁÆó

```python
# Element-wise operations (vectorized ‚Äî no loops needed!)
# ÈÄêÂÖÉÁ¥†ÈÅãÁÆóÔºàÂêëÈáèÂåñ‚Äî‚Äî‰∏çÈúÄË¶ÅËø¥ÂúàÔºÅÔºâ
rt_seconds = reaction_times
rt_ms = rt_seconds * 1000  # Convert to milliseconds ËΩâÊèõÁÇ∫ÊØ´Áßí
print(rt_ms)  # [452. 389. 521. 467. 498.]

# Descriptive statistics ÊèèËø∞ÊÄßÁµ±Ë®à
print(f"Mean RT: {np.mean(rt_seconds):.3f}s")
print(f"SD:      {np.std(rt_seconds):.3f}s")
print(f"Median:  {np.median(rt_seconds):.3f}s")
print(f"Min/Max: {np.min(rt_seconds):.3f} ‚Äì {np.max(rt_seconds):.3f}s")
```

### 4.3 Boolean Indexing & Filtering Â∏ÉÊûóÁ¥¢ÂºïËàáÁØ©ÈÅ∏

```python
# Filter outliers (RT > 500ms)
# ÁØ©ÈÅ∏Èõ¢Áæ§ÂÄºÔºàÂèçÊáâÊôÇÈñì > 500msÔºâ
outlier_mask = rt_seconds > 0.5
print(f"Outliers: {rt_seconds[outlier_mask]}")
print(f"Clean data: {rt_seconds[~outlier_mask]}")

# Count how many pass a threshold
fast_count = np.sum(rt_seconds < 0.45)
print(f"Fast responses: {fast_count}")
```

### 4.4 Random Number Generation Èö®Ê©üÊï∏ÁîüÊàê

```python
rng = np.random.default_rng(seed=42)  # Reproducible randomness ÂèØÈáçË§áÁöÑÈö®Ê©ü

# Shuffle trial order Êâì‰∫ÇË©¶È©óÈ†ÜÂ∫è
trial_types = np.array(["go", "go", "go", "nogo"] * 25)  # 100 trials
rng.shuffle(trial_types)

# Generate random stimulus positions ÁîüÊàêÈö®Ê©üÂà∫ÊøÄ‰ΩçÁΩÆ
x_positions = rng.uniform(-300, 300, size=50)  # 50 random x-coords
y_positions = rng.uniform(-300, 300, size=50)

# Sample from a normal distribution ÂæûÂ∏∏ÊÖãÂàÜ‰ΩàÂèñÊ®£
simulated_rt = rng.normal(loc=0.450, scale=0.080, size=200)
print(f"Simulated mean: {simulated_rt.mean():.3f}s")
```

---

## 5. Lab Activity: Install-Fest üöÄ
## 5. ÂØ¶‰ΩúÊ¥ªÂãïÔºöÂÆâË£ùÂ§ßÊúÉ üöÄ

**Goal ÁõÆÊ®ô**: Ensure every student has a working local environment.

Á¢∫‰øùÊØè‰ΩçÂêåÂ≠∏ÈÉΩÊúâÂèØÁî®ÁöÑÈñãÁôºÁí∞Â¢É„ÄÇ

### Checklist Ê™¢Êü•Ê∏ÖÂñÆ

- [ ] Install Miniforge or Anaconda
- [ ] Create `psychopy_env` with Python 3.10
- [ ] Install PsychoPy: `pip install psychopy`
- [ ] Install VS Code + Python extension
- [ ] Run the environment test script (see `week-01-README.md`)
- [ ] Verify NumPy works:

```python
import numpy as np
print(f"NumPy version: {np.__version__}")
data = np.random.default_rng(0).normal(0.5, 0.1, 100)
print(f"Mean: {data.mean():.4f}, SD: {data.std():.4f}")
```

---

## 6. Homework: "Hello Data"
## 6. ‰ΩúÊ•≠Ôºö„ÄåHello Data„Äç

> Write a Python script that generates a **synthetic dataset of reaction times** using NumPy.

Êí∞ÂØ´‰∏ÄÂÄã Python ËÖ≥Êú¨Ôºå‰ΩøÁî® NumPy ÁîüÊàê**ÂêàÊàêÁöÑÂèçÊáâÊôÇÈñìË≥áÊñôÈõÜ**„ÄÇ

### Requirements Ë¶ÅÊ±Ç

1. Generate 200 simulated reaction times from a normal distribution (mean = 450ms, SD = 80ms)
2. Add 10% "outlier" trials (RT > 800ms) to simulate lapses of attention
3. Print summary statistics (mean, SD, median, min, max)
4. Count and report the number of "fast" (< 300ms) and "slow" (> 600ms) responses
5. Save the data to a CSV file using NumPy

### Starter Code Ëµ∑ÂßãÁ®ãÂºèÁ¢º

```python
import numpy as np

def generate_synthetic_rt(n_trials=200, mean_rt=450, sd_rt=80, 
                          outlier_fraction=0.10, outlier_min=800, 
                          outlier_max=1500, seed=42):
    """
    Generate synthetic reaction time data.
    Áî¢ÁîüÂêàÊàêÁöÑÂèçÊáâÊôÇÈñìË≥áÊñô„ÄÇ
    """
    rng = np.random.default_rng(seed)
    
    # Step 1: Generate base RTs from normal distribution
    n_normal = int(n_trials * (1 - outlier_fraction))
    n_outlier = n_trials - n_normal
    
    normal_rt = rng.normal(loc=mean_rt, scale=sd_rt, size=n_normal)
    
    # Step 2: Generate outlier RTs
    # TODO: Generate outlier trials using rng.uniform()
    
    # Step 3: Combine and shuffle
    # TODO: Concatenate and shuffle all RTs
    
    # Step 4: Clip negative values (RT can't be negative)
    # TODO: Use np.clip() to ensure all RTs >= 50ms
    
    return all_rt

if __name__ == "__main__":
    rt_data = generate_synthetic_rt()
    
    # Print summary statistics
    print("=" * 40)
    print("  Synthetic RT Dataset Summary")
    print("=" * 40)
    # TODO: Print mean, SD, median, min, max
    
    # Count fast and slow responses
    # TODO: Use boolean indexing
    
    # Save to CSV
    # TODO: Use np.savetxt()
    print("Data saved to synthetic_rt.csv")
```

---

## References ÂèÉËÄÉË≥áÊñô

- **Python**: [https://docs.python.org/3/](https://docs.python.org/3/)
- **Anaconda**: [https://docs.anaconda.com/](https://docs.anaconda.com/)
- **Miniforge**: [https://github.com/conda-forge/miniforge](https://github.com/conda-forge/miniforge)
- **NumPy**: [https://numpy.org/doc/stable/](https://numpy.org/doc/stable/)
- **VS Code Python**: [https://code.visualstudio.com/docs/python/python-tutorial](https://code.visualstudio.com/docs/python/python-tutorial)
- **Reproducibility Crisis**: Open Science Collaboration (2015). *Estimating the reproducibility of psychological science.* Science, 349(6251), aac4716.
